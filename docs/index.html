---
layout: default
title: <span style="color:#ff4500">Interaction Graph-based Reddit Community Recommendation </span>
---
<!-- <style>
.heading1 {
    color: green;
    font-weight:700;
    font-size: 35px;
}
</style> -->

<head>
    <link rel="stylesheet" href="./css/styles.css" />
</head>

<div class = "main">
    <span style="color:black">r/DSC180 &#x2022;</span> <span style="color:gray">Made by: u/Pravar_Bhandari, u/Scott_Sutherland, u/Felicia_Chan, u/Ryan_Don</span><br>
    <span style="color:black;font-size:1.5em"> I want to create a Subreddit Recommendation System</span><br>
    <span style="color:black;"> As the title says, I want to create a Reddit Community Recommendation System. I know that this obviously already exists, but I want
    to try recommending subreddits to users by using user interactions as embeddings in my recommender system. Furthermore, I want this to be a graph-based
    recommender system. How would I go about creating something like this?
    </span><br>
    <span style="color:black">Suggested: </span> <span style="color:blue">r/TigerGraph</span>
</div>
<div class = "main" style = "margin-bottom: 10 px">
    <h2 class="heading" style="margin-top:5px"> Introduction </h2>
        <div class = "blank"><div class = "b">
            &nbsp&nbsp&nbsp&nbsp Social media has become the most important way for people to access information, connect with friends, and expand businesses.
            Around 70 percent of all Americans use social media to connect with each other and share information.
            The social media platform Reddit is a massive collection of forums where people can share news and content.
            Reddit is made up of more than a million communities known as subreddits; each subreddit consists of a different topic.
            Users in these subreddits can make posts and comments to interact with other users, essentially forming communities with specific interests.
            As of 2022, Reddit has 50 million daily active Reddit users worldwide. Reddit users are often recommended subreddits based
            on those they have visited or interacted with. Like many other social media platforms, Reddit's
            comment representation is a tree structure where separate replies to a comment are branches. We can think of conversation in one of these trees
            as a comment chain, that is, a set of comments where each one (apart from the first comment) is a reply to one preceding it.
            We will investigate the typical size, shape and diversity of users in each of these chains.<br><br>
            
            &nbsp&nbsp&nbsp&nbsp From a business point of view, the impact of this task would be in user acquisition and user retention. For current users, this would
            help expose them to subreddits they may be interested in, decreasing the likelihood of churn. For newer users without a few established
            subreddit communities they are a part of, immediately exposing them to similar communities may be beneficial in making them recurring
            users rather than one-time users. From a graph perspective, this problem is worth investigating as it can evaluate the relevancy of user
            interactions in a graph-like comment interaction structure as a basis for recommendation systems. We use a graph-based machine learning
            algorithm that assists in recommending subreddits to users based upon their interactions with other users in subreddits through comment chains.<br><br>
            
            &nbsp&nbsp&nbsp&nbsp Previous work has been done in the space of subreddit recommendation. In one attempt, a subreddit-to-subreddit interest network was built, where two
            subreddits are connected if a large portion of one subreddit's members are also active in the other. The model they use is K-means clustering, with
            another choosing to use the K-Nearest Neighbors algorithm. These examples along with others are not necessarily graph-based. Where graph community
            detection tasks of subreddits are used, the graphs are represented in relatively simple ways, primarily incorporating user and subreddit subscription
            relationships and using that data to make recommendations using "non-graphy" criteria such as similarity scores like Jaccard. By contrast, we look to
            use additional information which can be represented as graphs such as interactions between different users within subreddits in an attempt to leverage
            that interaction information as an indicator of userâ€™s affinity for different communities/subreddits. We aim to use collaborative filtering encoded
            within our algorithm with user interactions to then accurately recommend subreddits to users.<br><br>
            
            &nbsp&nbsp&nbsp&nbsp In order to create an algorithm ourselves, we use a dataset provided and maintained by Jason Baumgartner which can be downloaded via their website
            <a href="https://pushshift.io/">pushshift.io</a> at its <a href="https://files.pushshift.io/reddit/">data directory subdomain</a>. There, data for Reddit
            users, subreddits, posts and comments among other things are hosted in monthly time increments going back to Reddit's inception in 2005. In order to ensure
            we didn't face any hardware limitations, we opted to use all comments prior to 2011 (2005 - Dec. 2010). However, because the data across all time periods
            is formatted in the same way, our work could easily be scaled up simply by downloading and using the more recent files. From it, we build a graph with 2
            different types of nodes and 2 types of edges. Our 2 nodes are: User nodes and Subreddit nodes. Our first edge, interacted_with, connects
            users who interacted with other users. Second, the commented_in edge connects users to subreddits that they have interacted in via comments.<br><br>
            
            <table>
                <tr>
                    <td>Dataset Name</td>
                    <td>Contents</td>
                </tr>
                <tr>
                    <td>Users-Users</td>
                    <td>Connects users who interacted with one another</td>
                </tr>
                <tr>
                    <td>Subreddits</td>
                    <td>All Subreddits in the dataset</td>
                </tr>
                <tr>
                    <td>Subreddits-Comments</td>
                    <td>All comments and the subreddit they were made in</td>
                </tr>
                <tr>
                    <td>Users</td>
                    <td>All users in the dataset</td>
                </tr>
                <tr>
                    <td>Users-Comments</td>
                    <td>Comments and users who made the comments</td>
                </tr>
                <tr>
                    <td>Comments</td>
                    <td>All comments in the dataset</td>
                </tr>
                <tr>
                    <td>Comments-Comments</td>
                    <td>Comments that are connected in a comment chain</td>
                </tr>
            </table><br>
            
            &nbsp&nbsp&nbsp&nbsp All of the edges in this dataset are undirected, meaning that the relationship between any edge (v<sub>i</sub>, v<sub>j</sub>)
            in the graph is mutual. In total, our graph contains ~172,000 total vertices and ~1,200,000 edges. In a bit more detail, the graph contains 2,929
            unique subreddit vertices, and ~170,000 user vertices along with ~865,000 "interacted_with" edges and ~345,000 "commented_in" edges.<br><br>

            &nbsp&nbsp&nbsp&nbsp In particular, this dataset allows us to make this evaluation on a network like the one that can be derived from Reddit. That is, one which encodes
            information about the interaction of users with other users within pre-defined communities. However, as many social media platforms use very similar
            representations for the links between users, this data can hopefully allow us to make more broad claims about social graphs and their usefulness in making
            predictions about users preferred communities.<br>
            
            
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 1 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    
    <h2 class="heading" style="margin-top:5px"> Why Graph? </h2>
        <div class = "blank"><div class = "b">
            &nbsp&nbsp&nbsp&nbsp We decide to explore graph-based representations of data for good reason. Graph theory has existed for decades, but advancements in computing power
            and introduction of large-scale graph databases like TigerGraph have allowed applications of graph algorithms to a wide range of domains. Traditional
            data methods, like representing data tabularly, are less effective in representing complex relationships; rows are  observations, columns are  variables.
            This can be limiting for data that has many associated variables and complex relationships, as tabular data is less effective. We believe that
            user-subreddit and user-user relationships would be better represented as graphs, which makes representation more flexible. Especially for Reddit, 
            like many other social media platforms, their comment representation is a tree structure where separate replies to a comment are branches, which is well 
            represented by graphs.
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 2 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    
    <h2 class="heading" style="margin-top:5px"> Data Preparation </h2>
        <div class = "blank"><div class = "b">
            &nbsp&nbsp&nbsp&nbsp  In order to fully leverage the graph structure of our data, we use <a href="https://www.tigergraph.com/">TigerGraph</a>,
            a graph analytics platform which provides a myriad of tools and resources for graph-based data science
            and machine learning, making it a valuable solution for us. The data we downloaded from pushshift,
            each comment is given in the same format as the following example:<br>
            
            <div style = "padding-left:100px"><p class="center">{<br>
                "author": "RaptorLog",<br>
                "author_flair_css_class": "",<br>
                "author_flair_text": "ro ru ",<br>
                "body": "Oh, I have been going crazy...",<br>
                "can_gild": true,<br>
                "controversiality": 0,<br>
                "created_utc": 1506816002,<br>
                "distinguished": null,<br>
                "edited": false,<br>
                "gilded": 0,<br>
                "id":"dnqik36",<br>
                "is_submitter": true,<br>
                "link_id": "t3_73g6fg",<br>
                "parent_id": "t1_dnqf2cj",<br>
                "permalink": "/r/duolingo/comments/73g6fg/...",<br>
                "retrieved_on": 1509189607,<br>
                "score": 32,<br>
                "stickied": false,<br>
                "subreddit": "duolingo",<br>
                "subreddit_id": "t5_2t6ze"<br>
            }</p><br></div>
            
            &nbsp&nbsp&nbsp&nbsp There is a lot of interesting data here, but we are most interested in the user who made the comment, the subreddit it was posted to and the
            parent comment if any. Due to the fact that any comment on Reddit is either a child of a post of another comment, we can use this parent
            relationship to generate the comment chain graph structure we will set up in TigerGraph. We then use the author field to create edges between
            user vertices identified by those author names and the comment id's as well as subreddit to comment edges using the subreddit name as an identifier
            for the subreddit vertices. Once we have the correct files specifying those vertices and edges, we simply use TigerGraph's tools for uploading and
            mapping the data to generate our graph.<br><br>
            
            After loading our data to TigerGraph, we develop a schema that looks like so: <br>
            <img src="./images/schema.png" /><br>
            This schema consists of two vertex types (Subreddit, User) and 2 edge types (interacted_with, commented_in)<br>
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 3 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    <h2 class="heading" style="margin-top:5px;text-align:center"> Exploratory Data Analysis </h2>
        <div class = "blank"><div class = "b">
            Once we prepare and load our data, we do some exploratory data analysis to better understand the data we are working with. First, we look into some more
            general statistics like the top 10 largest subreddits with the most unique users:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/subreddit_unique_users.png">
                <figcaption>Fig 1 - Top 10 subreddits with Unique Users</figcaption>
            </figure><br>
            
            Looking at Figure 1, subreddits that seem more broad and common like 'gaming' and 'pics' are in the top 10 subreddits. 
            Since they are broad, it is more likely that users will join these and be interested in these subreddits. In Figure 2, 
            we look into the distribution of the number of comments made by users:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/distr_num_comments.png">
                <figcaption>Fig 2 - Distribution of number of comments made by users</figcaption>
            </figure><br>
            We see that 27% of users have made 1 comment, 41% of users have made between 2 and 10 comments, and 31% of users have made more than 10 comments.<br>

            Next, we look into the karma of users. On Reddit, karma is a score of a user/comment that is determined by the sum of all upvotes minus the sum of
            all downvotes. It is usually displayed publically next to the upvote and downvote buttons. First we look into the average karma for a comment by
            subreddit:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/avg_karma_subreddit.png">
                <figcaption>Fig 3 - Average Karma for a Comment by Subreddit</figcaption>
            </figure><br>
            In Figure 3, we can see that most of these subreddits have an average karma for comments in the subreddit between 0 and 3.
            Next, we look into the average karma for a comment by user:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/avg_karma_users.png">
                <figcaption>Fig 4 - Average Karma for a Comment by User</figcaption>
            </figure><br>
            In Figure 4, we see that once again, a large majority of users have an average karma between 0 and 5 for their comments.
            Finally, we also analyze the distribution of users by karma:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/distr_karma_user.png">
                <figcaption>Fig 5 - Distribution of Users by Karma</figcaption>
            </figure><br>
            
            Figure 5 shows that a majority of users have between 1 and 100 karma associated with their accounts, while few users have negative karma.
            After this, we aim to look at the volume of comments by day. From our dataset, we find that the majority of comments are made in the month of December.
            Looking at Figure 6:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/volume_by_day.png">
                <figcaption>Fig 6 - Volume of Comments by Day (December)</figcaption>
            </figure><br>
            This doesn't give us much insight into large trends, but we do see that for the most part, there are several days where the volume of comments seems 
            to be relatively similar to one another, meaning that there does not seem to be a special relationship between day of month and number of comments.

            Finally, we delve a bit deeper into comment chains, as that is where the biggest focus of our model is. We find that we have 942,558 comment 
            chains in our data. Figure 7 shows the distribution of comment chain lengths.<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/cmt_chain_length_distr.png">
                <figcaption>Fig 7 - Distribution of Comment Chain Lengths</figcaption>
            </figure><br>
            
            From Figure 7, we can see that the majority of comments do not actually belong to a comment chain. This means that the comment was posted and no-one 
            replied. These data are likely not very useful in generating meaningful metrics for recommendation based on user comment interactions.

            However, 45% of the comment data are part of chains with 41% being 'small' chains of only 2 - 10 comments and the other 4% being long chains with over 10
            comments. We can examine the distributions of both of these groups:<br><br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/cmt_chain_length_distr_clean.png">
                <figcaption>Fig 8 - Distribution of Comment Chain Lengths (2-10 and 10+)</figcaption>
            </figure><br>
            As we might expect, we generally have less chains of longer lengths. In short, there are mostly smaller chains in the data but the distribution is 
            heavily right-skewed due to some very long chains.<br>
            Now we look at some data such as the number of users in each chain and the number of times users tend to interact in a chain. 
            Figure 9 details the number of unique users per chain:<br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/distr_users_chains.png">
                <figcaption>Fig 9 - Distribution of Unique Users in Chains</figcaption>
            </figure><br>
            
            Next, we look at the ratio between the number of unique users in a chain and the total number of comments in that chain. This tells us 
            how unique the set of users participating in a chain is. Smaller ratios means there is less diversity. We find that the chains are generally 
            quite diverse as, on average, the number of unique users is very close to the total number of comments. However, because we are including 
            chains of length one which the ration is guaranteed to be 1.0 for, this value is quite skewed. We remove those and try again:<br>
            
            <table>
                <tr>
                    <td>Minimum Number in Chain</td>
                    <td>count</td>
                    <td>mean</td>
                    <td>std</td>
                    <td>min</td>
                </tr>
                <tr>
                    <td>1</td>
                    <td>428186.0</td>
                    <td>0.864</td>
                    <td>0.202</td>
                    <td>0.016</td>
                </tr>
                <tr>
                    <td>2</td>
                    <td>203798.0</td>
                    <td>0.829</td>
                    <td>0.202</td>
                    <td>0.016</td>
                </tr>
                <tr>
                    <td>3</td>
                    <td>117313.0</td>
                    <td>0.811</td>
                    <td>0.197</td>
                    <td>0.016</td>
                </tr>
                <tr>
                    <td>4</td>
                    <td>76377.0</td>
                    <td>0.800</td>
                    <td>0.191</td>
                    <td>0.016</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td>54273.0</td>
                    <td>0.793</td>
                    <td>0.186</td>
                    <td>0.016</td>
                </tr>
                <tr>
                    <td>6</td>
                    <td>40719.0</td>
                    <td>0.788</td>
                    <td>0.181</td>
                    <td>0.074</td>
                </tr>
                <tr>
                    <td>7</td>
                    <td>32033.0</td>
                    <td>0.784</td>
                    <td>0.176</td>
                    <td>0.085</td>
                </tr>
                <tr>
                    <td>8</td>
                    <td>25871.0</td>
                    <td>0.781</td>
                    <td>0.173</td>
                    <td>0.085</td>
                </tr>
                <tr>
                    <td>9</td>
                    <td>21444.0</td>
                    <td>0.779</td>
                    <td>0.17</td>
                    <td>0.085</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td>18123.0</td>
                    <td>0.777</td>
                    <td>0.166</td>
                    <td>0.085</td>
                </tr>
            </table><br>
            
            This is more indicative of the data we wanted to see. Now, as we move towards larger and larger chains, the average ratio of unique users 
            seems to plataeu at ~0.78 as indicated by Figure 10.<br><br>
            <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                <img src="./images/avg_unique_users_chain.png">
                <figcaption>Fig 10 - Average Ratio of Unique Users in Chains</figcaption>
            </figure><br>
            
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 4 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    <h2 class="heading" style="margin-top:5px"> Baselines </h2>
        <div class = "blank"><div class = "b">
            &nbsp&nbsp&nbsp&nbsp After completing our EDA, we aim to develop baseline models for community detection so as to compare these to our final model. 
            We develop baseline models: K-Nearest Neighbors, a recommender system using Jaccard similarity, and a simple popularity prediction model. 
            These baselines are not necessarily graph-based, but they help us to set and measure the baseline to then build upon for our final model.<br>
            <div class = "blank"><ol>
                <li>The K-Nearest Neighbors algorithm we develop uses cosine similarity as the metric, and chooses 20 neighbors. Cosine similarity is a measure
                    of similarity between two data points in a plane, and in a KNN is used to determine the distance between two points. This can be found 
                    mathematically as follows:<br>
                    <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                        <img src="./images/knn_equation.PNG">
                    </figure><br>
                </li>
                <li> The recommender system we develop uses Jaccard similarity to recommend subreddits to users. The Jaccard index is used to gauge the similarity 
                    and diversity of sets, and can be determined mathematically as follows:
                    <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                        <img src="./images/jaccard_equation.PNG">
                    </figure><br>
                </li>
                <li> A final baseline we tried was a simple popularity predictor model, which recommends users the most popular subreddits that they are not already 
                    subscribed to.
                </li>
            </ol></div>
            
            We then build simple models in TigerGraph to calculate several different metrics based on our graph network:<br>
            <ul>
                <li>Closeness for Users: a measure of the average farness (inverse distance) to all other user nodes. 
                    Nodes with a high closeness score have the shortest distance to all other nodes. The closeness of a node <math>x</math> is determined by:<br>
                    <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                        <img src="./images/closeness_user.PNG">
                    </figure><br>
                    where $N$ is the number of nodes in the graph, and $d(y,x)$ is the length of the shortest path between user vertices x and y. <br>
                </li>
                <li>Betweenness for Users: This is a measure of the percentage of shortest paths to other users that must go through a specific user node. 
                    A user node with high betweenness is likely to be aware of what is going on in multiple circles. The equation for betweenness of a given 
                    node $u$ is:
                    <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                        <img src="./images/between_user.PNG">
                    </figure><br>
                    where $\sigma_{v,w}$ is the total number of shortest paths from node $v$ to node $w$, and $\sigma_{v,w}(u)$ is the total number of shortest 
                    paths from node $v$ to node $w$ that pass through $u$.
                </li>
                <li> Eigenvector for Users: eigenvector centrality is a measure of the influence of a node in a network. A high score means that a node is connected 
                    to many nodes who have high scores. For a given graph $G := (V,E)$ with $|V|$ vertices, where $A = (a_{v,t})$ is the adjacency matrix 
                    (i.e. $(a_{v,t})$ = 1 if the vertex v is linked to vertex t and 0 otherwise.). We can find the eigenvector centrality using:
                    <figure style = "display:block;margin-left: auto;margin-right: auto;width:50%">
                        <img src="./images/eigenvector_user.PNG">
                    </figure><br>
                </li>
            </ul>
            
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 5 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            <h3 class="heading" style="margin-top:5px"> Non-Graph Algorithms </h3>
            <div class = "blank"><div class = "b">
                This is the Non-Graph Algorithms section.
                <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            </div></div>
            <h3 class="heading" style="margin-top:5px"> Centrality Algorithms </h3>
            <div class = "blank"><div class = "b">
                This is the Centrality Algorithms section.
                <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            </div></div>
            <h3 class="heading" style="margin-top:5px"> Community Detection Algorithms </h3>
            <div class = "blank"><div class = "b">
                This is the Community Detection Algorithms section.
                <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            </div></div>
        </div></div>
    
    <h2 class="heading" style="margin-top:5px"> Final Model </h2>
        <div class = "blank"><div class = "b">
            Here lies our final model...
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    
    <h2 class="heading" style="margin-top:5px"> Results & Evaluation </h2>
        <div class = "blank"><div class = "b">
            Here lies our results...
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
        </div></div>
    
    <h2 class="heading" style="margin-top:5px"> Conclusion </h2>
        <div class = "blank"><div class = "b">
            Here lies our conclusion...
            <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            <h3 class="heading" style="margin-top:5px"> Future Work/Next Steps </h3>
            <div class = "blank"><div class = "b">
                This is the Future Work/Next Steps section.
                <div><img src="./images/up_arrow-removebg-preview.png" style="width:30px;height:30px;position:relative;top:10px" /> 15 <img src="./images/down_arrow-removebg-preview.png " style="width:30px;height:30px;position:relative;top:10px"/></div>
            </div></div>
        </div></div>
    <div>&nbsp;</div>
</div>

<!-- <div style="background-color:white;border-radius: 10px;padding-left:10px;color:black">
    <h2 style="color:#ff4500"> Baselines </h2>
    <h3 style="color:#ff4500"> Non-Graph Algorithms </h3>
        Sample Text
    <h3 style="color:#ff4500"> Centrality Algorithms </h3>
        Sample Text
    <h3 style="color:#ff4500"> Community Detection Algorithms </h3>
        Sample Text
    <h3 style="color:#ff4500"> Network Statistics K-Means Model </h3>
        Sample Text
</div> -->

<!-- <div style="background-color:white;border-radius: 10px;padding-left:10px;color:black">
    <h2 style="color:#ff4500"> Final Model </h2>
        Sample Text
</div>

<div style="background-color:white;border-radius: 10px;padding-left:10px;color:black">
    <h2 style="color:#ff4500"> Results & Evaluation </h2>
        Sample Text
</div>

<div style="background-color:white;border-radius: 10px;padding-left:10px;color:black">
    <h2 style="color:#ff4500"> Conclusion </h2>
        Sample Text
    <h2 style="color:#ff4500"> Future Work & Next Steps </h2>
        Sample Text
</div> -->

